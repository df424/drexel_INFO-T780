{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Trees (Part 1)</h1>\n",
    "<p>Given a data set we can use machine learning to create decision trees to make a complex decision based on data.  In this assignment we learn decision trees to classify  </p>\n",
    "<p>We are given the following dataset to work with.</p>\n",
    "<table>\n",
    "    <tr><th>No.</th><th>Outlook</th><th>Temperature</th><th>Humidity</th><th>Windy</th><th>Class</th></tr>\n",
    "    <tr><td>1</td><td>sunny</td><td>hot</td><td>high</td><td>false</td><td>N</td></tr>\n",
    "    <tr><td>2</td><td>sunny</td><td>hot</td> <td>high</td> <td>true</td> <td>N</td></tr>\n",
    "    <tr><td>3</td><td>overcast</td><td>hot</td> <td>high</td> <td>false</td> <td>P</td></tr>\n",
    "    <tr><td>4</td><td>rain</td><td>mild</td> <td>high</td> <td>false</td> <td>P</td></tr>\n",
    "    <tr><td>5</td><td>rain</td><td>cool</td> <td>normal</td> <td>false</td> <td>P</td></tr>\n",
    "    <tr><td>6</td><td>rain</td><td>cool</td> <td>normal</td> <td>true</td> <td>N</td></tr>\n",
    "    <tr><td>7</td><td>overcast</td><td>cool</td> <td>normal</td> <td>true</td> <td>P</td></tr>\n",
    "    <tr><td>8</td><td>sunny</td><td>mild</td> <td>high</td> <td>false</td> <td>N</td></tr>\n",
    "    <tr><td>9</td><td>sunny</td><td>cool</td> <td>normal</td> <td>false</td> <td>P</td></tr>\n",
    "    <tr><td>10</td><td>rain</td><td>mild</td> <td>normal</td> <td>false</td> <td>P</td></tr>\n",
    "    <tr><td>11</td><td>sunny</td><td>mild</td> <td>normal</td> <td>true</td> <td>P</td></tr>\n",
    "    <tr><td>12</td><td>overcast</td><td>mild</td> <td>high</td> <td>true</td> <td>P</td></tr>\n",
    "    <tr><td>13</td><td>overcast</td><td>hot</td> <td>normal</td> <td>false</td> <td>P</td></tr>\n",
    "    <tr><td>14</td><td>rain</td><td>mild</td> <td>high</td> <td>true</td> <td>N</td></tr>\n",
    "</table>\n",
    "\n",
    "<p>Notice we have a number of enumerated features.  For instance the <b>outlook</b> category can be either sunny, overcast or rain.  The <b>temperature</b> can be hot, mild or cool, the <b>humidty</b> can be high or normal.  To make it easier to handle this programatically we can transform these features into <b>1-hot vectors</b>; or in the case of the humidty just a simple boolean.  So instead of our original feature set lets use the following list of binary variables: Sunny, Overcast, Rainy, Hot Mild, Cool, Humid, Windy.  With this in mind we can use the table shown below as the input to our algorithms.</p>\n",
    "\n",
    "<table>\n",
    "    <tr><th>No.</th><th>Sunny</th><th>Overcast</th><th>Rainy</th><th>Hot</th><th>Mild</th><th>Cool</th><th>Humid</th><th>Windy</th><th>Class</th></tr>\n",
    "    <tr><td>1</td> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>N</th></tr>\n",
    "    <tr><td>2</td> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>T</th> <th>N</th></tr>\n",
    "    <tr><td>3</td> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>P</th></tr>\n",
    "    <tr><td>4</td> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>F</th> <th>P</th></tr>\n",
    "    <tr><td>5</td> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>P</th></tr>\n",
    "    <tr><td>6</td> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>N</th></tr>\n",
    "    <tr><td>7</td> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>P</th></tr>\n",
    "    <tr><td>8</td> <th>T</th> <th>F</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>F</th> <th>N</th></tr> \n",
    "    <tr><td>9</td> <th>T</th> <th>F</th> <th>F</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>P</th></tr>\n",
    "    <tr><td>10</td> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>F</th> <th>P</th></tr>\n",
    "    <tr><td>11</td> <th>T</th> <th>F</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>P</th></tr>\n",
    "    <tr><td>12</td> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>T</th> <th>P</th></tr>\n",
    "    <tr><td>13</td> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>F</th> <th>F</th> <th>F</th> <th>F</th> <th>P</th></tr>\n",
    "    <tr><td>14</td> <th>F</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>F</th> <th>T</th> <th>T</th> <th>N</th></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"randomdecisiontree\">Decision Trees - Random Feature Selection</h3>\n",
    "<p>When learning a decision tree we can use the following algorithm...</p><br>\n",
    "<code>While there are data points left to classify:\n",
    "    1. Pick a feature or features to branch on.\n",
    "    2. Divide the input data based on the decision.\n",
    "    3. If either set of the divided data has a single class then let that be the leaf of the tree.</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let this be our input vector where we have used 1 to represent a true boolean and 0 to represent a false boolean.\n",
    "X = np.array([[1, 0, 0, 1, 0, 0, 1, 0],\n",
    "              [1, 0, 0, 1, 0, 0, 1, 1],\n",
    "              [0, 1, 0, 1, 0, 0, 1, 0],\n",
    "              [0, 0, 1, 0, 1, 0, 1, 0],\n",
    "              [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 1, 0, 0, 1, 0, 1],\n",
    "              [0, 1, 0, 0, 0, 1, 0, 1],\n",
    "              [1, 0, 0, 0, 1, 0, 1, 0],\n",
    "              [1, 0, 0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 1, 0, 1, 0, 0, 0],\n",
    "              [1, 0, 0, 0, 1, 0, 0, 1],\n",
    "              [0, 1, 0, 0, 1, 0, 1, 1],\n",
    "              [0, 1, 0, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 0, 1, 0, 1, 1]])\n",
    "\n",
    "# Let this be our vector of labels where 1 is positive and 0 is negative.\n",
    "Y = np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"other_data\">Exploring Another Dataset</h2>\n",
    "\n",
    "<p>It turns out that keras has a few other data sets built-in.  Lets look at another one.  The MNIST database of handwritten digits is one of the classic beginner ML problems.  The data is 60,000 grayscale images each of which are a handwritten number between 0 and 9.  So our labels then are the set of numbers between 0 and 9.  Keras has other built-in datasets which can be accessed <a href=\"https://keras.io/datasets/\">here.</a></p>\n",
    "\n",
    "<p>Anyway lets load the datasets.  This time I use the more traditional X and Y variables names that we see in a lot of the ML literature.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e989a05093d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load data into training sets and validation sets.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_v\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# load data into training sets and validation sets.\n",
    "(X_t, Y_t), (X_v, Y_v) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Before trying something new lets train the last network we made on this new data set to see what kind of accuracy we can get.</p>\n",
    "\n",
    "<p>To do these we recompile the model which will reset the weights.  Otherwise we would be starting from where we left off training the fashion data set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile the model to reset it.\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Train the old model using the new data set.\n",
    "history = model.fit(X_t, Y_t, epochs=10, validation_data=(X_v, Y_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results.\n",
    "plotHistory(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
