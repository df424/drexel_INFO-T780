{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Assignment 4 - NLP</h1>\n",
    "<p>In this assignment we investage two different pretrained word embeddings to see what we can do with them.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the gensim downloader module to load the pretrained embeddings.\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Loading the \"glove-wiki-gigaword-300\" model</h5>\n",
    "<p>To load the model we can just use one of gensim's pretrained models.</p>\n",
    "<p>In this case we are using the glove-wiki-gigaword-300 model that is trained from six billion words taken from Wikipedia and the Gigaword data set.</p>\n",
    "<p>We can load the trained model with the following function call</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_model = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Using the Model</h5>\n",
    "<p>Gensim has a lot of convinient functions that we can use to get results from our models.</p>\n",
    "<p>For instance we can compare two words using the similarity or distance functions.</p>\n",
    "<p>The words with the highest similarity or lowest distance will be most similar and the words with the lowest similarity or highest distance will be the most dissimilar.</p>\n",
    "<p>Notice that the similarity and distance pretty much sum up to 1 as you would expect.  Also notice the second example where I compare \"stay\" and \"leave\" they have a very high similarity despite being opposites.  This is expected since these words are scored based on their occurances in texts and not their meaning.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity= 0.3981698, Distance=0.6018302142620087\n",
      "Similarity= 0.7483314, Distance=0.2516685724258423\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity= \" + str(gw_model.similarity('wizard', 'magic')) + \", Distance=\" + str(gw_model.distance('wizard', 'magic')))\n",
    "print(\"Similarity= \" + str(gw_model.similarity('leave', 'stay')) + \", Distance=\" + str(gw_model.distance('leave', 'stay')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can also query the model to find the n most similar words.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('oz', 0.5637089014053345), ('sorcerer', 0.533085823059082), ('magician', 0.4954693913459778), ('magical', 0.49252745509147644), ('wicked', 0.4775075912475586)]\n"
     ]
    }
   ],
   "source": [
    "print(gw_model.most_similar('wizard', topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Or we can give the model a list of words and ask which one doesn't match.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(gw_model.doesnt_match(['wizard', 'magic', 'castle', 'dog']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Or we can find words that are more similar to one word than a given word.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evil', 'potter', 'adventures', 'magical', 'witch', 'oz', 'wicked', 'magician', 'merlin', 'sorcerer', 'pinball', 'scarecrow', 'wizardry', 'voldemort', 'gandalf', 'sorceress', 'shazam']\n"
     ]
    }
   ],
   "source": [
    "print(gw_model.closer_than('wizard', 'magic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Loading the glove-twitter-200 model</h5>\n",
    "<p>To compare two modles lets load the glove-twitter-200 model that is trained on a set of two billion tweets.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_model = api.load('glove-twitter-200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now lets run the same four queries and compare the results and try to examine the differences.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity= 0.5412099, Distance=0.458790123462677\n",
      "Similarity= 0.732284, Distance=0.2677159905433655\n",
      "[('magic', 0.5412098169326782), ('witch', 0.5009379982948303), ('master', 0.48517435789108276), ('magician', 0.4800835847854614), ('dorothy', 0.4708351492881775)]\n",
      "dog\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity= \" + str(twitter_model.similarity('wizard', 'magic')) + \", Distance=\" + str(twitter_model.distance('wizard', 'magic')))\n",
    "print(\"Similarity= \" + str(twitter_model.similarity('leave', 'stay')) + \", Distance=\" + str(twitter_model.distance('leave', 'stay')))\n",
    "print(twitter_model.most_similar('wizard', topn=5))\n",
    "print(twitter_model.doesnt_match(['wizard', 'magic', 'castle', 'dog']))\n",
    "print(twitter_model.closer_than('wizard', 'magic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So if we examine the differences between the two queries we see that the words wizard and magic are much more similar than with the wikipedia set.  I think this is probably due to the nature of wikipedia where instead of referning magic in an article about a character that is a wizard, it would link to the artical wizard and let you go read about it there.</p>\n",
    "<p>Notice that it was still correctly able to identify dog as the outlier in the doesn't match example.  We would expect this as not many twitter users probably talk about their dogs being magic, although I suppose some might.  Lets test it!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs and wizards: 0.31513983\n"
     ]
    }
   ],
   "source": [
    "print(\"dogs and wizards: \" + str(twitter_model.similarity('dog', 'wizard')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It looks as though at least some twitter users must think their dogs are magical...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
